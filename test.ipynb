{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [6 6]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "points = [(1, 2), (3, 4), (5, 6), (7, 8)]\n",
    "points = np.array(points)\n",
    "\n",
    "print(points - points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"\"\n",
      "libGL error: MESA-LOADER: failed to open vmwgfx: /usr/lib/dri/vmwgfx_dri.so: 无法打开共享目标文件: 没有那个文件或目录 (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: vmwgfx\n",
      "libGL error: MESA-LOADER: failed to open swrast: /usr/lib/dri/swrast_dri.so: 无法打开共享目标文件: 没有那个文件或目录 (search paths /usr/lib/x86_64-linux-gnu/dri:\\$${ORIGIN}/dri:/usr/lib/dri, suffix _dri)\n",
      "libGL error: failed to load driver: swrast\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m cap \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mVideoCapture(\u001b[38;5;241m0\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mCAP_V4L2)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(cap\u001b[38;5;241m.\u001b[39misOpened()):\n\u001b[0;32m----> 5\u001b[0m     retval, frame \u001b[38;5;241m=\u001b[39m \u001b[43mcap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLive\u001b[39m\u001b[38;5;124m'\u001b[39m, frame)\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# if cv2.waitKey(1) & 0xFF == ord('q'):\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m#     break\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 释放资源\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0, cv2.CAP_V4L2)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    retval, frame = cap.read()\n",
    "    cv2.imshow('Live', frame)\n",
    "  \n",
    "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "    #     break\n",
    "\n",
    "# 释放资源\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "template_image = cv2.imread('/home/lmz/opencv/Live_screenshot_22.07.2024.jpg')\n",
    "\n",
    "# 将图像从BGR转换到HSV色彩空间\n",
    "template_image_hsv = cv2.cvtColor(template_image, cv2.COLOR_BGR2HSV)    \n",
    "\n",
    "lower_red1 = np.array([0, 120, 70])\n",
    "upper_red1 = np.array([10, 255, 255])\n",
    "lower_red2 = np.array([170, 120, 70])\n",
    "upper_red2 = np.array([180, 255, 255])\n",
    "\n",
    "# 创建红色掩膜\n",
    "mask1 = cv2.inRange(template_image_hsv, lower_red1, upper_red1)\n",
    "mask2 = cv2.inRange(template_image_hsv, lower_red2, upper_red2)\n",
    "mask = mask1 + mask2\n",
    "\n",
    "# 对原图像和掩膜进行位运算\n",
    "red_regions = cv2.bitwise_and(template_image_hsv, template_image_hsv, mask=mask)\n",
    "\n",
    "# 转换为灰度图像\n",
    "gray = cv2.cvtColor(red_regions, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 使用高斯模糊平滑图像\n",
    "blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "\n",
    "# 形态学闭操作\n",
    "new_image = cv2.morphologyEx(blurred, cv2.MORPH_CLOSE, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3)))\n",
    "\n",
    "# 应用边缘检测\n",
    "template_edges = cv2.Canny(new_image, 50, 150)\n",
    "\n",
    "# 寻找轮廓\n",
    "template_contours, _ = cv2.findContours(template_edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for contour in template_contours:\n",
    "\n",
    "    # 计算轮廓的周长\n",
    "    perimeter = cv2.arcLength(contour, True)\n",
    "    \n",
    "    # 多边形拟合\n",
    "    approx = cv2.approxPolyDP(contour, 0.05 * perimeter, True)\n",
    "    # print(approx)\n",
    "    # 如果多边形有四个顶点，则认为它是一个四边形\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        # 获取四个顶点坐标\n",
    "        points = approx.reshape(4, 2)\n",
    "        # print(points)\n",
    "        cv2.drawContours(template_image, [points], -1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155.04\n"
     ]
    }
   ],
   "source": [
    "print(11.4 * 13.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.6.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
